1. **Messages**
   - Definition 
     #### Messages refer to structured data exchanged between a user and an AI model.These messages contain inputs, responses, or context
   - Purpose
     #### To facilitate interaction and provide the necessary context or instructions for the model to generate an appropriate response
   - Example
     ``` python
     messages = [
     {"role": "user", "content": "What is AI?"},
     {"role": "assistant", "content": "AI stands for Artificial Intelligence, which refers to systems that mimic human-like decision-making."}
     ]
     ```

2. **Model**
   - Definition
     #### The AI model specifies the architecture or version of an AI system being used for creating responses
   - Purpose
     #### To define the type of AI to process user requests and generate responses
   - Example
     ``` python
     model = "gpt-3.5-turbo"
     response = openai.ChatCompletion.create(model=model, messages=messages)
     ```

3. **Max Completion Tokens**
   - Definition 
     #### This parameter controls the maximum number of tokens the model can generate in the response
   - Purpose
     #### To limit the response length, ensuring it fits within a predefined token budget.
   - Example
     ```python
     response = openai.ChatCompletion.create(
     model="gpt-3.5-turbo",
     messages=messages,
     max_tokens=50  # Response limited to 50 tokens
     )
     ```
4. **n**
   - Definition
     #### The number of response completions the model should generate.
   - Purpose
     #### To receive multiple variations of a response for a single query.
   - Example
     ```python
        response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=messages,
        n=3  # Generate 3 responses
        )
        for i, choice in enumerate(response['choices']):
        print(f"Response {i+1}: {choice['message']['content']}")
        ```

5. **Strem**
    - Definition
      #### A parameter to enable real-time response streaming instead of waiting for the entire response to be generated.
    - Purpose
      #### Useful for displaying outputs incrementally, especially for long responses.
    - Example
      ```python
        response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=messages,
        stream=True  # Enable streaming
        )
        for chunk in response:
            print(chunk["choices"][0]["delta"]["content"], end="")
      ```
6. **Temperature**
    - Definition
      #### A parameter that controls the randomness of the model’s responses.
      - #### Lower values produce deterministic outputs.
      - #### Higher values introduce more randomness.
    - Purpose
      #### To control response diversity for factual queries.
    - Example
      ```python
      response = openai.ChatCompletion.create(
      model="gpt-3.5-turbo",
      messages=messages,
      temperature=0.8  # Introduce creativity/randomness
      )
      ```
7. **Top_p**
    - Definition
      #### An alternative to temperature that uses nucleus sampling. It limits the model’s token choices to the top p percentage of probabilities.
    - Purpose
      #### To fine-tune response diversity while ensuring coherent outputs.
    - Example
      ```python
      response = openai.ChatCompletion.create(
      model="gpt-3.5-turbo",
      messages=messages,
      top_p=0.9  # Use top 90% probability tokens
      )
      ```
8. **Tools**
    - Definition
      #### External APIs or functions that the AI model can call to enhance its capabilities
    - Purpose
      #### To integrate specialized tools for handling tasks beyond the model’s default capabilities.
    - Example
      ```python
        def calculator(a, b):
        return a + b
      #AI can call this tool during conversation
      tools = {"calculator": calculator}
      response = tools["calculator"](5, 10)  # AI uses the tool
      print(response)  # Output: 15
      ```
