{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsFgTwTLwgdLSgZbZaKA0l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minahil-official/Quater-2/blob/main/Project_2_LangChain_RAG_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **LangChain RAG with Google Gemini Flash and Pinecone**\n",
        "\n"
      ],
      "metadata": {
        "id": "0hMoRovfsuC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installations"
      ],
      "metadata": {
        "id": "t3cnWr-Cw_uX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-pinecone langchain-google-genai"
      ],
      "metadata": {
        "id": "BP8Xsh1Uw8Nz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuring Pinecone Api"
      ],
      "metadata": {
        "id": "_TeNOVQYxPCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "pinecone_api_key = userdata.get('Pinecon_API')\n",
        "pc = Pinecone(api_key=pinecone_api_key)"
      ],
      "metadata": {
        "id": "f3rr_8Y2s8oF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating Index**"
      ],
      "metadata": {
        "id": "zEnfrWlOxdm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"rag-project\"\n",
        "pc.delete_index(index_name)\n",
        "\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,\n",
        "    metric='cosine',\n",
        "    spec  = ServerlessSpec(cloud=\"aws\",region=\"us-east-1\"),\n",
        ")\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "JSqPyjnbtLZy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating Embeddings Using Embedding model**"
      ],
      "metadata": {
        "id": "v_ihE-fjx58u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import os\n",
        "\n",
        "GEMINI_KEY = userdata.get(\"GOOGLE_API_KEY_2\")\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\",google_api_key=GEMINI_KEY )"
      ],
      "metadata": {
        "id": "eNCzVEDXtVQT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = embeddings.embed_query(\"Building a Rag project! \")"
      ],
      "metadata": {
        "id": "pxU7nfi9upbL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yal3Ds9_u1Cn",
        "outputId": "4b4bb2da-132c-4a26-8825-db838df6a13f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.005886509083211422,\n",
              " -0.01920737698674202,\n",
              " -0.01310189813375473,\n",
              " -0.03790365159511566,\n",
              " -0.003551947884261608]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating Vector Store with Pinecone**"
      ],
      "metadata": {
        "id": "64maa_QMySHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ],
      "metadata": {
        "id": "CAHYcd-8vBUO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I have chocolate chip pancake and scrambled eggs for breakfast\",\n",
        "    metadata={\"source\": \"personal\", \"meal\": \"breakfast\"}\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"LangChain is a framework for building applications with LLMs (Large Language Models), such as GPT. It provides tools to manage chains, agents, and memory for building more advanced AI applications.\",\n",
        "    metadata={\"topic\": \"LangChain\", \"category\": \"AI Framework\"}\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Agentic AI refers to autonomous AI systems that are capable of decision-making, learning, and adaptation in real-world environments without needing constant human intervention.\",\n",
        "    metadata={\"topic\": \"Agentic AI\", \"category\": \"Artificial Intelligence\", \"importance\": \"High\"}\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"In the latest world news, a new tech company has developed an innovative AI that is able to solve real-world problems faster than previous models, pushing the boundaries of automation and efficiency.\",\n",
        "    metadata={\"topic\": \"Tech News\", \"date\": \"2025-01-02\", \"company\": \"Innovative AI Company\"}\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"The use of AI in healthcare is growing rapidly. Recent advancements in diagnostic AI tools are helping doctors identify diseases more accurately and faster, significantly improving patient outcomes.\",\n",
        "    metadata={\"topic\": \"Healthcare AI\", \"category\": \"Medical Technology\", \"impact\": \"Positive\"}\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"LangChain offers a wide range of tools to work with LLMs. This includes support for document search, question-answering systems, and memory management to make intelligent agents more effective in real-world tasks.\",\n",
        "    metadata={\"topic\": \"LangChain\", \"category\": \"AI Tools\", \"use_case\": \"Advanced workflows\"}\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"Agentic AI is becoming increasingly important in industries like autonomous vehicles, robotics, and smart cities, where real-time decision-making and adaptability are crucial for success.\",\n",
        "    metadata={\"topic\": \"Agentic AI\", \"category\": \"Industry Applications\", \"industries\": [\"Autonomous Vehicles\", \"Robotics\", \"Smart Cities\"]}\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"A new world record has been set for the fastest internet speed, with researchers breaking through previous limitations using advanced fiber-optic technology, promising faster and more efficient global communication.\",\n",
        "    metadata={\"topic\": \"Tech News\", \"category\": \"Innovation\", \"record\": \"Fastest Internet Speed\", \"date\": \"2025-01-02\"}\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"In a recent study, AI-powered chatbots have been shown to outperform human customer service agents in resolving technical issues, reducing wait times and improving customer satisfaction.\",\n",
        "    metadata={\"topic\": \"AI in Customer Service\", \"category\": \"Business Technology\", \"impact\": \"High\"}\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"LangChain continues to evolve with new integrations, including support for databases, APIs, and external data sources, enabling more complex and efficient workflows for AI applications.\",\n",
        "    metadata={\"topic\": \"LangChain\", \"category\": \"Development\", \"features\": [\"Database Integration\", \"API Support\", \"External Data Sources\"]}\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1, document_2, document_3, document_4, document_5,\n",
        "    document_6, document_7, document_8, document_9, document_10\n",
        "]"
      ],
      "metadata": {
        "id": "GM0RQu5Ovg5H"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(  documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dhW0H6Yvlqp",
        "outputId": "f72d423a-5126-458e-82a3-8b8ec25c35b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Documents and giving IDs"
      ],
      "metadata": {
        "id": "Zo_vSe9myr3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "uuid4()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPx1H1mHvogJ",
        "outputId": "0acc2f8d-017b-42ab-d9f6-609bbcdd2aaa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UUID('c5cd4623-5fa4-45f7-a0db-85a489b75032')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uuids = [str(uuid4()) for i in range (len(documents))]\n",
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7XUc90fvtQy",
        "outputId": "096c018c-ec91-43a2-d12f-d06cd38a9a74"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2641c889-08b7-4c61-8b05-cd31712c4e3c',\n",
              " '5f23815c-9479-4dd8-bd70-471ca6b41735',\n",
              " '13e31ea9-9102-4816-aec9-44d820150609',\n",
              " '7392720b-45ab-4aa7-8fd2-3186276a8a4d',\n",
              " 'f95dfd7e-b4f0-481a-819a-c95c76202797',\n",
              " '826413ab-580a-403d-ad6a-b57cbf5404c2',\n",
              " '273e4def-213e-46f3-a39a-6e934195f68b',\n",
              " 'cded9dde-1617-49bd-8ec8-0595a9e237ab',\n",
              " '0c1df380-fba2-4aa5-b880-4e0175d9eedb',\n",
              " 'd823773a-da6a-40dd-9e3e-fdc679e4ee3a']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performng Similarity search"
      ],
      "metadata": {
        "id": "FmHID_RmzFRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_result = vector_store.similarity_search(\n",
        "    \"What is langchain\", k=7,)\n",
        "print(vector_result[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6Ttepzqvwoi",
        "outputId": "0e321fcb-511d-4b7f-cd58-88033fd1f16f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain is a framework for building applications with LLMs (Large Language Models), such as GPT. It provides tools to manage chains, agents, and memory for building more advanced AI applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Contextual Answers with Google Generative AI"
      ],
      "metadata": {
        "id": "wtlSqHEjzZWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Using Langchain**"
      ],
      "metadata": {
        "id": "SmXGId1-znFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "bbJbRHZLv3PV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_answer(question):\n",
        "\n",
        "  vector_result = vector_store.similarity_search(question, k=5)\n",
        "\n",
        "  llm = ChatGoogleGenerativeAI(\n",
        "      api_key=GEMINI_KEY,\n",
        "      model = \"gemini-2.0-flash-exp\",\n",
        "      max_tokens= 100,\n",
        "      temperature=0.7\n",
        "  )\n",
        "\n",
        "  prompt1= PromptTemplate(\n",
        "      input_variables=[\"question\"],\n",
        "      template = \"Using this data {vector_result} . Answer the following question: \\n\\n{question}\"\n",
        "  )\n",
        "  chain1= prompt1 | llm\n",
        "\n",
        "  final_answer = chain1.invoke({\"vector_result\": vector_result, \"question\": question})\n",
        "\n",
        "  return final_answer"
      ],
      "metadata": {
        "id": "0hm6J4Dmv-5n"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = user_answer(\"What's the latest news?\")"
      ],
      "metadata": {
        "id": "1u5txNi6wFnF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "uIXgBgZ8wI81",
        "outputId": "e71558e1-60ed-421f-938a-3903740dbb8e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the provided data, here's the latest news:\n\n*   **Innovative AI Company Develops Advanced AI:** A new tech company has created an AI that solves real-world problems faster than previous models, advancing automation and efficiency (from document ID `7392720b-45ab-4aa7-8fd2-3186276a8a4d`).\n*   **New World Record for Fastest Internet Speed:** Researchers"
          },
          "metadata": {}
        }
      ]
    }
  ]
}